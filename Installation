This document provides a step-by-step guide to using Ollama, a powerful tool for interacting with
large language models (LLMs). We'll cover the installation process, how to use the Ollama API with
Curl, and explore the differences between two popular models: Llama3 and Gemma:2b.

Step 1: Ollama Installation
To begin, you'll need to install Ollama on your system. Follow these steps:
1. Download Llama from [https://github.com/ollama/ollama](https://github.com/ollama/ollama)
2. Install it on your system.
3. Run Ollama using the command "ollama run ollama3".
Once Ollama is running, you can connect to it and start asking questions
